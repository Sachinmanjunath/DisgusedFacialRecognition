{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#2.3.1'\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#2.3.1'\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#2.4.3'\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-vggface==0.6 in d:\\essentials\\python\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.14 in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (1.10.1)\n",
      "Requirement already satisfied: h5py in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (3.8.0)\n",
      "Requirement already satisfied: pillow in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (9.4.0)\n",
      "Requirement already satisfied: keras in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (2.12.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pratheek\\appdata\\roaming\\python\\python311\\site-packages (from keras-vggface==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in d:\\essentials\\python\\lib\\site-packages (from keras-vggface==0.6) (6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications==1.0.8 in d:\\essentials\\python\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\essentials\\python\\lib\\site-packages (from keras_applications==1.0.8) (1.23.5)\n",
      "Requirement already satisfied: h5py in d:\\essentials\\python\\lib\\site-packages (from keras_applications==1.0.8) (3.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12.0 #2.3.1\n",
    "!pip install tensorflow-gpu==2.12.0 #2.3.1\n",
    "!pip install keras==2.12.0 #2.4.3\n",
    "!pip install keras-vggface==0.6\n",
    "!pip install keras_applications==1.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace #from keras.utils.layer_utils import get_source_inputs\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger,EarlyStopping\n",
    "from keras_vggface.utils import decode_predictions\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_Path,batch_size):\n",
    "\n",
    "\n",
    "  train_data_dir='D:/Programs/Project_new_vgg/dataset/train'\n",
    "  test_data_dir = 'D:/Programs/Project_new_vgg/dataset/test'\n",
    "  val_data_dir = 'D:/Programs/Project_new_vgg/dataset/val'\n",
    "\n",
    "\n",
    "\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   \n",
    "                                   zoom_range=0.2,\n",
    "                                  \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "                        train_data_dir,\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "  print(train_generator.classes)\n",
    "  print(train_generator.class_indices)\n",
    "\n",
    "\n",
    "  val_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                     rotation_range=40,   \n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "                        val_data_dir,\n",
    "                      \n",
    "                        target_size=(224,224),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "\n",
    "  print(val_generator.classes)\n",
    "  print(val_generator.class_indices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  test_generator = test_datagen.flow_from_directory(\n",
    "                        test_data_dir,\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        seed=42,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "\n",
    "  print(test_generator.classes)\n",
    "  print(test_generator.class_indices)\n",
    "  return train_generator,val_generator,test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  vggface = VGGFace(model='vgg16')\n",
    "  vggface.summary()\n",
    "  return vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(old_model):\n",
    "\n",
    "  inp = old_model.input     # make a reference to VGG's input layer\n",
    "  num_classes=75\n",
    "\n",
    "  new_classification_layer=Dense(num_classes,activation='softmax')\n",
    "  new_model=Sequential()\n",
    "\n",
    "  # connect the above new layer to the second to last layer in VGG, and make a reference to it\n",
    "  out = new_classification_layer(old_model.layers[-2].output)\n",
    "\n",
    "# create a new network between inp and out\n",
    "  model_new = Model(inp, out)\n",
    "\n",
    "  # make all layers untrainable by freezing weights \n",
    "  for l, layer in enumerate(model_new.layers):\n",
    "    layer.trainable = False\n",
    "  # Enable the last three dense layers for  training\n",
    "  for l, layer in enumerate(model_new.layers[-6:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "  model_new.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "  \n",
    "  return model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fine_tuned_vgg16_model(model_new, load_weight,train_data,val_data,batch_size,checkpoint_path):\n",
    "\n",
    "  #%load_ext tensorboard\n",
    "  #log_dir = \"/content/drive/MyDrive/ICDFD_VGG/log_imfdb_dense/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  #%tensorboard --logdir '/content/drive/MyDrive/ICDFD_VGG/log_imfdb_dense/'\n",
    "  #log_dir = \"/content/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  #%tensorboard --logdir '/content/logs/'\n",
    "  #Model loading\n",
    "  if load_weight==True:\n",
    "    model_new.load_weights(\"D:/Programs/Project_new_vgg/logs/Augmented_IIITD_new_60_20_0_V3-0002.h5\")  # load the latest model and change the checkpoint name and retrain where u left off\n",
    "\n",
    "  # Create a callback that saves the model's weights\n",
    "  cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 mode='min',\n",
    "                                                 period=1)\n",
    "  \n",
    "\n",
    "  csv_logger=CSVLogger('D:/Programs/Project_new_vgg/DAR_60_20_20_V2.csv',separator=',',append=True)\n",
    "\n",
    "  steps_per_epoch =  np.floor(train_data.n / batch_size)     # total number of images in train /batch size\n",
    "  validation_steps =  np.floor(val_data.n / batch_size)     # total number of images in test /batch size\n",
    "\n",
    "  nepochs = 150   # earlier 150\n",
    "   \n",
    " \n",
    "\n",
    "\n",
    "  early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)  #erlier val_loss\n",
    "  \n",
    "  #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "  model_new.fit_generator(train_data,\n",
    "                          epochs=nepochs,      #steps_per_epoch=steps_per_epoch,\n",
    "                          validation_data=val_data,\n",
    "                          validation_steps=validation_steps,\n",
    "                          callbacks=[cp_callback,early_stop,csv_logger])#,cp_callback,tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "  model_new.save('VGGFace_mtcnn_Augmented_IIITD_Model_60_20_20_V1.h5')\n",
    "  model_new.save_weights('VGGFace_mtcnn_Augmented_IIITD_finetuned_weights_60_20_20_V1.h5')\n",
    " # np.save('/content/drive/My Drive/my_history_Cov_unfrezzed_.npy',model_new.history)\n",
    "  return model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc6/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " fc7/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 2622)              10742334  \n",
      "                                                                 \n",
      " fc8/softmax (Activation)    (None, 2622)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc6/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " fc7/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 2622)              10742334  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 75)                196725    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,199,603\n",
      "Trainable params: 130,484,915\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model()\n",
    "model_new=fine_tune(model)\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9382 images belonging to 75 classes.\n",
      "[ 0  0  0 ... 74 74 74]\n",
      "{'P1': 0, 'P10': 1, 'P11': 2, 'P12': 3, 'P13': 4, 'P14': 5, 'P15': 6, 'P16': 7, 'P17': 8, 'P18': 9, 'P19': 10, 'P2': 11, 'P20': 12, 'P21': 13, 'P22': 14, 'P23': 15, 'P24': 16, 'P25': 17, 'P26': 18, 'P27': 19, 'P28': 20, 'P29': 21, 'P3': 22, 'P30': 23, 'P31': 24, 'P32': 25, 'P33': 26, 'P34': 27, 'P35': 28, 'P36': 29, 'P37': 30, 'P38': 31, 'P39': 32, 'P4': 33, 'P40': 34, 'P41': 35, 'P42': 36, 'P43': 37, 'P44': 38, 'P45': 39, 'P46': 40, 'P47': 41, 'P48': 42, 'P49': 43, 'P5': 44, 'P50': 45, 'P51': 46, 'P52': 47, 'P53': 48, 'P54': 49, 'P55': 50, 'P56': 51, 'P57': 52, 'P58': 53, 'P59': 54, 'P6': 55, 'P60': 56, 'P61': 57, 'P62': 58, 'P63': 59, 'P64': 60, 'P65': 61, 'P66': 62, 'P67': 63, 'P68': 64, 'P69': 65, 'P7': 66, 'P70': 67, 'P71': 68, 'P72': 69, 'P73': 70, 'P74': 71, 'P75': 72, 'P8': 73, 'P9': 74}\n",
      "Found 3105 images belonging to 75 classes.\n",
      "[ 0  0  0 ... 74 74 74]\n",
      "{'P1': 0, 'P10': 1, 'P11': 2, 'P12': 3, 'P13': 4, 'P14': 5, 'P15': 6, 'P16': 7, 'P17': 8, 'P18': 9, 'P19': 10, 'P2': 11, 'P20': 12, 'P21': 13, 'P22': 14, 'P23': 15, 'P24': 16, 'P25': 17, 'P26': 18, 'P27': 19, 'P28': 20, 'P29': 21, 'P3': 22, 'P30': 23, 'P31': 24, 'P32': 25, 'P33': 26, 'P34': 27, 'P35': 28, 'P36': 29, 'P37': 30, 'P38': 31, 'P39': 32, 'P4': 33, 'P40': 34, 'P41': 35, 'P42': 36, 'P43': 37, 'P44': 38, 'P45': 39, 'P46': 40, 'P47': 41, 'P48': 42, 'P49': 43, 'P5': 44, 'P50': 45, 'P51': 46, 'P52': 47, 'P53': 48, 'P54': 49, 'P55': 50, 'P56': 51, 'P57': 52, 'P58': 53, 'P59': 54, 'P6': 55, 'P60': 56, 'P61': 57, 'P62': 58, 'P63': 59, 'P64': 60, 'P65': 61, 'P66': 62, 'P67': 63, 'P68': 64, 'P69': 65, 'P7': 66, 'P70': 67, 'P71': 68, 'P72': 69, 'P73': 70, 'P74': 71, 'P75': 72, 'P8': 73, 'P9': 74}\n",
      "Found 3203 images belonging to 75 classes.\n",
      "[ 0  0  0 ... 74 74 74]\n",
      "{'P1': 0, 'P10': 1, 'P11': 2, 'P12': 3, 'P13': 4, 'P14': 5, 'P15': 6, 'P16': 7, 'P17': 8, 'P18': 9, 'P19': 10, 'P2': 11, 'P20': 12, 'P21': 13, 'P22': 14, 'P23': 15, 'P24': 16, 'P25': 17, 'P26': 18, 'P27': 19, 'P28': 20, 'P29': 21, 'P3': 22, 'P30': 23, 'P31': 24, 'P32': 25, 'P33': 26, 'P34': 27, 'P35': 28, 'P36': 29, 'P37': 30, 'P38': 31, 'P39': 32, 'P4': 33, 'P40': 34, 'P41': 35, 'P42': 36, 'P43': 37, 'P44': 38, 'P45': 39, 'P46': 40, 'P47': 41, 'P48': 42, 'P49': 43, 'P5': 44, 'P50': 45, 'P51': 46, 'P52': 47, 'P53': 48, 'P54': 49, 'P55': 50, 'P56': 51, 'P57': 52, 'P58': 53, 'P59': 54, 'P6': 55, 'P60': 56, 'P61': 57, 'P62': 58, 'P63': 59, 'P64': 60, 'P65': 61, 'P66': 62, 'P67': 63, 'P68': 64, 'P69': 65, 'P7': 66, 'P70': 67, 'P71': 68, 'P72': 69, 'P73': 70, 'P74': 71, 'P75': 72, 'P8': 73, 'P9': 74}\n",
      "fc6\n",
      "fc6/relu\n",
      "fc7\n",
      "fc7/relu\n",
      "fc8\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "dataset_path=\"D:\\Programs\\Project_new_vgg\\dataset\"\n",
    "root_dir=\"D:\\Programs\\Project_new_vgg\"\n",
    "\n",
    "train_data,val_data,test_data=load_dataset(dataset_path,batch_size)\n",
    "for names in model_new.layers:\n",
    "  if names.trainable==True:\n",
    "    print(names.name)\n",
    "load_epoch_weights= False #True  # if True change the below checkpoint name before training.\n",
    "checkpoint_path = root_dir+\"/logs/Augmented_IIITD_new_60_20_0_V3-{epoch:04d}.h5\"     #earlier\n",
    "#checkpoint_path = dataset_path+\"/logs/ICDFD_mtcnn_VGGFace_new-{epoch:04d}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRATHEEK\\AppData\\Local\\Temp\\ipykernel_6680\\1316762373.py:35: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_new.fit_generator(train_data,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "294/294 [==============================] - 3034s 10s/step - loss: 4.0072 - accuracy: 0.1769 - val_loss: 3.4190 - val_accuracy: 0.3351\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 2389s 8s/step - loss: 2.8481 - accuracy: 0.4858 - val_loss: 2.2940 - val_accuracy: 0.6082\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 2482s 8s/step - loss: 1.9625 - accuracy: 0.6549 - val_loss: 1.6644 - val_accuracy: 0.7043\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_new\u001b[39m=\u001b[39mtrain_fine_tuned_vgg16_model(model_new,load_epoch_weights,train_data,val_data,batch_size,checkpoint_path)\n",
      "Cell \u001b[1;32mIn[14], line 35\u001b[0m, in \u001b[0;36mtrain_fine_tuned_vgg16_model\u001b[1;34m(model_new, load_weight, train_data, val_data, batch_size, checkpoint_path)\u001b[0m\n\u001b[0;32m     31\u001b[0m early_stop\u001b[39m=\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)  \u001b[39m#erlier val_loss\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m model_new\u001b[39m.\u001b[39;49mfit_generator(train_data,\n\u001b[0;32m     36\u001b[0m                         epochs\u001b[39m=\u001b[39;49mnepochs,      \u001b[39m#steps_per_epoch=steps_per_epoch,\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mval_data,\n\u001b[0;32m     38\u001b[0m                         validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m     39\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[cp_callback,early_stop,csv_logger])\u001b[39m#,cp_callback,tensorboard_callback])\u001b[39;00m\n\u001b[0;32m     43\u001b[0m model_new\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mVGGFace_mtcnn_Augmented_IIITD_Model_60_20_20_V1.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m model_new\u001b[39m.\u001b[39msave_weights(\u001b[39m'\u001b[39m\u001b[39mVGGFace_mtcnn_Augmented_IIITD_finetuned_weights_60_20_20_V1.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\keras\\engine\\training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2625\u001b[0m \n\u001b[0;32m   2626\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2629\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2630\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2631\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2632\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2633\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2634\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2635\u001b[0m )\n\u001b[1;32m-> 2636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2637\u001b[0m     generator,\n\u001b[0;32m   2638\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2639\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2640\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2641\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2642\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2643\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2644\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2645\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2646\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2647\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2648\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2649\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2650\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Essentials\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_new=train_fine_tuned_vgg16_model(model_new,load_epoch_weights,train_data,val_data,batch_size,checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
